Multimodal Access - W3C/**/@import url("/2008/site/css/advanced");/**/W3CStandardsParticipateMembershipAbout W3CSite NavigationWeb of DevicesVoice BrowsingDevice Independence and Content AdaptationMultimodal AccessWeb and TVSkipW3C » Standards » Web of Devices » Multimodal AccessMultimodal AccessOn this page ?what is multimodal access•capabilities of multimodal access•examples•learn more•recent press releasesâ€¢-->current status of specifications and groupsWhat is Multimodal Access?Multimodal technology is a promising candidate of future human machineinterfaces which can improve Web accessibility within various conditions andenvironments of the users. For example, these days we can access the Webusing various devices including mobile phones, PDA, car navigation system andhome appliances. However, the concrete access methods strongly depend on thetype of devices and services, and are quite different from each other. Someof those applications are based on W3C standards. However, many are based onproprietary platforms and technologies. So a global and universalstandardized mechanism which applies to various kinds of devices and servicesis required to materialize "One Web" which lets any personto access a specific information using any modalities on any devices fromanywhere at any time.Capabilities of Multimodal AccessThe capabilities of multimodal applications include voice and GUIinteraction. Standards for multimodal interfaces should be scalable toenable richer capabilities for subsequent generations of multimodaldevices.To encourage rapid adoption, the same content can bedesigned for use on both old/simple and new/multimodal devices.For example, people with new multimodal devices will get to experiencetheir multimodal capabilities, while users with old simple deviceswill get to use the keypad and/or stylus in the same way as now.Users of multimodal devices will be able to provide input via speech,handwriting or keystrokes with output presented via displays,pre-recorded and synthetic speech/audio and tactile mechanisms likevibrators and Braille strips.Application developers will be able to provide an effective userinterface for whichever modes the user selects.ExamplesAs a result of increasingly capable networks, devices, and speechrecognition technology, the number of existing multimodal applications,especially mobile applications, is rapidly accelerating:Multimodal Voice Search integrating GUI and speechVoice control on mobile devicesAddress input on GPS systemsMultimodal in-car systems for accessing navigation and audio/visual controlNote that almost all of those multimodal applications have appeared inthe last two years.Many of them are based on proprietary platforms and technologies, sostandardization of multimodal interfaces is needed for global interoperability.Learn MoreThe mission of the Multimodal Interaction Activity is to develop open standards that enable the following vision:Extending the Web to allow multiple modes of interaction: GUI, Speech, Vision, Pen, Gestures, Haptic interfaces, ...Anyone, Anywhere, Any device, Any time: Accessible through the user's preferred modes of interaction with services that adaptto the device, user and environmental conditionsVisit the Multimodal Interaction Activity home page.Recent W3C Press Releases and Member TestimonialsDigital Ink Standard Enhances Device Integration20 September 2011Current Status of SpecificationsLearn more about the current status of specifications relatedto:InkMLMultimodal Web ApplicationsThese W3C Groups areworking on the related specifications:Multimodal Interaction Working GroupContact:Kazuyuki Ashimura<ashimura@w3.org>Current StatusInkMLMultimodal Web ApplicationsUse ItTutorialsBusiness CaseSoftwareFooter NavigationNavigationHomeStandardsParticipateMembershipAbout W3CContact W3CContactHelp and FAQDonateSite MapFeedbackW3C UpdatesCopyright © 2013 W3C ® (MIT, ERCIM,Keio, Beihang) Usage policiesapply.////]]>